{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc39b23-9813-4914-ab12-129f6158671e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install ollama\n",
    "#!pip install 'diffusers[torch]' transformers\n",
    "#!pip install TTS\n",
    "#!pip install moviepy\n",
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b857cb-c01f-460f-ae49-2476b4e79e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export DISABLE_TELEMETRY=YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "815ce59e-8839-4ed1-9a79-1a758160323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe0a351c-8dd2-4533-8ff4-4241d3d7660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('approved_stories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103ebb35-3f62-4f48-b599-fbf11fccfb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>ups</th>\n",
       "      <th>approval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>74233</td>\n",
       "      <td>TIFU by having my reddit history revealed by J...</td>\n",
       "      <td>This happened to me yesterday and I'm still ba...</td>\n",
       "      <td>85249</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>35184</td>\n",
       "      <td>TIFU by getting Reddit banned in Russia</td>\n",
       "      <td>Today Reddit was blocked in Russia, and I am t...</td>\n",
       "      <td>64262</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>73236</td>\n",
       "      <td>TIFU by not telling my wife our son was coming...</td>\n",
       "      <td>This happened Sunday night.\\n\\n\\n\\nMy oldest s...</td>\n",
       "      <td>49877</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>41777</td>\n",
       "      <td>TIFU by sitting in the wrong class for an enti...</td>\n",
       "      <td>I'm in my third year of University taking engi...</td>\n",
       "      <td>48085</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>77396</td>\n",
       "      <td>TIFU by trying to play my dad’s didgeridoo.</td>\n",
       "      <td>So my dad has had this didgeridoo in the house...</td>\n",
       "      <td>46906</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328</th>\n",
       "      <td>9994</td>\n",
       "      <td>76707</td>\n",
       "      <td>TIFU by Getting a Sodastream for my Parents fo...</td>\n",
       "      <td>This happened about 10 minutes ago. So several...</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>9995</td>\n",
       "      <td>42961</td>\n",
       "      <td>TIFUpdate by making a dumb joke to myself whic...</td>\n",
       "      <td>[Some of you may remember my stupid joke](http...</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>9996</td>\n",
       "      <td>71249</td>\n",
       "      <td>TIFU by pressing the wrong button</td>\n",
       "      <td>So by some stroke of luck, I was invited to at...</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7331</th>\n",
       "      <td>9997</td>\n",
       "      <td>73043</td>\n",
       "      <td>TIFU my first edible experience</td>\n",
       "      <td>Mandatory \"This actually happened about a year...</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7332</th>\n",
       "      <td>9998</td>\n",
       "      <td>36945</td>\n",
       "      <td>TIFU by holding the door open for an old man a...</td>\n",
       "      <td>I'm still stunned and have no idea what I did ...</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7333 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0  \\\n",
       "0                0       74233   \n",
       "1                3       35184   \n",
       "2                4       73236   \n",
       "3                5       41777   \n",
       "4                6       77396   \n",
       "...            ...         ...   \n",
       "7328          9994       76707   \n",
       "7329          9995       42961   \n",
       "7330          9996       71249   \n",
       "7331          9997       73043   \n",
       "7332          9998       36945   \n",
       "\n",
       "                                                  title  \\\n",
       "0     TIFU by having my reddit history revealed by J...   \n",
       "1               TIFU by getting Reddit banned in Russia   \n",
       "2     TIFU by not telling my wife our son was coming...   \n",
       "3     TIFU by sitting in the wrong class for an enti...   \n",
       "4           TIFU by trying to play my dad’s didgeridoo.   \n",
       "...                                                 ...   \n",
       "7328  TIFU by Getting a Sodastream for my Parents fo...   \n",
       "7329  TIFUpdate by making a dumb joke to myself whic...   \n",
       "7330                  TIFU by pressing the wrong button   \n",
       "7331                    TIFU my first edible experience   \n",
       "7332  TIFU by holding the door open for an old man a...   \n",
       "\n",
       "                                               selftext    ups  approval  \n",
       "0     This happened to me yesterday and I'm still ba...  85249      True  \n",
       "1     Today Reddit was blocked in Russia, and I am t...  64262      True  \n",
       "2     This happened Sunday night.\\n\\n\\n\\nMy oldest s...  49877      True  \n",
       "3     I'm in my third year of University taking engi...  48085      True  \n",
       "4     So my dad has had this didgeridoo in the house...  46906      True  \n",
       "...                                                 ...    ...       ...  \n",
       "7328  This happened about 10 minutes ago. So several...    130      True  \n",
       "7329  [Some of you may remember my stupid joke](http...    130      True  \n",
       "7330  So by some stroke of luck, I was invited to at...    130      True  \n",
       "7331  Mandatory \"This actually happened about a year...    130      True  \n",
       "7332  I'm still stunned and have no idea what I did ...    130      True  \n",
       "\n",
       "[7333 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8973e693-07b9-4061-91e3-42f4f40e84f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "storynum = randint(1, 7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39ed39-be4a-4ce0-8af2-c07cd92c4fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9095a42-83cf-4cc7-8a63-8ad53b68ddbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd rather orally pleasure a cactus than go through the traumatic event was a dinner 'party' a second time around. \n",
      "\n",
      "So I'm dating an American girl who's family is Moroccan. I swear on all that's holy and good in this world that her name is actually Jennifer, but with this spamming of her name, we can call her Penny. Moroccan family's will occasionally make a dish and sit in a large circle around the one large dish and all eat out of it. Last night, I was invited over the house to celebrate a group birthday for the father and son. Mrs.Penny, a rather rude bitch of a woman, had slaved in the kitchen for hours preparing an amazing dish as it was a very special night. Not only was it a birthday 'party' but it was also the first time i would meet the family. The dish was spectacular with meats, and garnish  all placed artfully within a large clay bowl. This event was very very special to the family and I was really hoping to impress Penny because her period had ended 3 days ago and our over active sex drives were craving the dirty... We had only had sex a few times before but always in secret. Tonight would be different as the family was gonna go see a film and leave us at the house.\n",
      "\n",
      "Our subtle interactions throughout the day, where we were constantly under supervision, meant one thing: i was gonna be tongue punching her fart box in a few hours and my god does she have a fine ass. It ranks high on the 'Kate The Biology Teacher' scale for those who would understand. \n",
      "Finally, the time comes for us to sit around the table and this is when I was gonna shine. Look classy. Be polite and show the family how awesome I was. We all took hands to pray cos that's what the family is into. I sat next to her little brother who has a grudge match to outmuscle me so he squeezes my hand very very tightly, and Penny on the other side squeezing my hand tight because she can't help but be nervous for the first time I'm meeting the family. \n",
      "\n",
      "I'm sitting cross legged in front of this steaming dish filled with onions and red pepper seasoning and/or whatever else was making my nose twitch and my eyes water. My god I knew it was coming but I couldn't turn left or right due to the people and I seriously panicked because I could not for the life of me free my\n",
      "Hands. I tried to stifle the sneeze, but all I succeed in doing was blasting the greenest, thickest and most vile nose concoction directly in the main dish. I literally could not have hit my mark better if my nose was a military grade sniper rifle. \n",
      "Needless to say, I was mortified, and my entire body went cold. Like I was watching somebody I loved die in third person. I stood up mid prayer as no body noticed except for the sister who loudly gasped, awkwardly said, 'oh god, I'm terribly sorry.' , grabbed my coat and left. Didn't take long for Penny to text me, 'I think you've made a lasting impression on my family.'\n",
      "\n",
      "Yep. FML.  \n"
     ]
    }
   ],
   "source": [
    "inspo = df.iloc[storynum].selftext\n",
    "\n",
    "\n",
    "\n",
    "print(inspo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b10d56-41ec-48dc-b894-3805ee9668c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "timed out waiting for llama runner to start - progress 0.00 - ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m script \u001b[38;5;241m=\u001b[39m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mllama3:70b-instruct\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[38;5;124;43mYou are the world\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms best social media video script writer. Take the following story and turn it into an original viral short form video voiceover script for tiktok.\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43mThe script should take no more than two minutes to narrate and should have a hook at the beginning to catch the viewer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms attention in the first 5 seconds that isn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt cheesy.\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43mFor each scene, write a very detailed description of the scene in a way that could be used by a stable diffusion ai model to generate an image to accompany the voiceover.\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43mThe voiceover should convey the entire story completly on it\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms own, don\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt rely on the image descriptions to tell the story.\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43mOnly for the image description come up with appropriate first and last names of any characters and always use their full name for each scene also describe them physically for each scene. Here\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms the story: \u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minspo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/storytime-simple/env/lib/python3.10/site-packages/ollama/_client.py:126\u001b[0m, in \u001b[0;36mClient.generate\u001b[0;34m(self, model, prompt, system, template, context, stream, raw, format, images, options, keep_alive)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model:\n\u001b[1;32m    124\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m RequestError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmust provide a model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/generate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemplate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m_encode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeep_alive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m  \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/storytime-simple/env/lib/python3.10/site-packages/ollama/_client.py:97\u001b[0m, in \u001b[0;36mClient._request_stream\u001b[0;34m(self, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_stream\u001b[39m(\n\u001b[1;32m     92\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     93\u001b[0m   \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m     94\u001b[0m   stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     95\u001b[0m   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     96\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], Iterator[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]]]:\n\u001b[0;32m---> 97\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/workspace/storytime-simple/env/lib/python3.10/site-packages/ollama/_client.py:73\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, method, url, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m   response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 73\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mResponseError\u001b[0m: timed out waiting for llama runner to start - progress 0.00 - "
     ]
    }
   ],
   "source": [
    "script = ollama.generate(model='llama3:70b-instruct', \n",
    "                         prompt='''You are the world's best social media video script writer. Take the following story and turn it into an original viral short form video voiceover script for tiktok.\n",
    "The script should take no more than two minutes to narrate and should have a hook at the beginning to catch the viewer's attention in the first 5 seconds that isn't cheesy.\n",
    "For each scene, write a very detailed description of the scene in a way that could be used by a stable diffusion ai model to generate an image to accompany the voiceover.\n",
    "The voiceover should convey the entire story completly on it's own, don't rely on the image descriptions to tell the story.\n",
    "Only for the image description come up with appropriate first and last names of any characters and always use their full name for each scene also describe them physically for each scene. Here's the story: ''' + inspo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827b5bd2-f858-4660-b688-8566d48d9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(script['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dffeb4-45da-4c9e-9534-02e72417fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('promptguide.txt', 'r') as file:\n",
    "    promptguide = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54232af-7ff0-4f7d-b405-46936c1a79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scriptwdesc = ollama.generate(model='llama3:70b-instruct', \n",
    "                         prompt='''Take the image descriptions and the voiceovers in the script and change the image discriptions using the techniques in the prompt guide i have attached below the script. the output should be the edited script (voiceovers and descriptions).\n",
    "copy the voiceovers as is for each scene and ignore any afterword after the script. DO NOT DESCRIBE WHAT THE GUIDE DOES OR SUMMARIZE THE GUIDE!!! DON'T FORGET TO INCLUDE THE ORIGINAL VOICEOVER FROM THE SCRIPT!\n",
    "''' +\n",
    "'''Here's the prompt guide: ''' + promptguide + ' heres the script where you need to edit the image descriptions but leave the voiceover the same: Script:' + script['response'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62599fd-717f-4ef3-a9ca-9ded9e992b55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(scriptwdesc['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc8a03c-fda7-486e-b73f-d28da19ca529",
   "metadata": {},
   "outputs": [],
   "source": [
    "scriptjson = ollama.generate(model='llama3:70b-instruct', \n",
    "                             format='json',\n",
    "                             keep_alive=1,\n",
    "                         prompt='''Take the following script and turn it into json format, it should be an array containing scenes, each scene should contain a imageDescription and voiceover field. in the voiceover string change any single quotes to double quotes.\n",
    "                         here's the script: ''' + scriptwdesc['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb070c-a951-454c-b4ac-d21ebe6317c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scriptjson['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda249c1-1538-403b-87c5-d06ffb754e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scriptdict = json.loads(scriptjson['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c6f29-2c72-47c0-a81a-e5d54e591553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb265c1-82f9-41a3-9871-a940059649a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline, DPMSolverMultistepScheduler\n",
    "import torch\n",
    "\n",
    "pipeline = StableDiffusionXLPipeline.from_single_file(\n",
    "    \"Juggernaut_X_RunDiffusion.safetensors\",\n",
    "    torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipeline = pipeline.to(\"cuda\")\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17970eaf-2543-499d-800c-f5509731febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt = \"High resolution Portrait of a stylish African woman in urban setting, short brunette hair, bold red lipstick, colors striking red and deep blacks, style modern fashion, mood confident, lighting high contrast with sharp shadows, perspective frontal view, texture leather jacket and smooth skin\"\n",
    "def make_image(prompt):\n",
    "    images = pipeline(prompt= '(anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), ' + prompt,\n",
    "        negative_prompt=\"naked, penis, pussy, porn, nudity, (worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)\",\n",
    "        active_tags=[],\n",
    "        inactive_tags=[],\n",
    "        width=832,\n",
    "        height=1216,\n",
    "        num_inference_steps=30,\n",
    "        guidance_scale=7.0,\n",
    "        preserve_init_image_color_profile=False,\n",
    "        upscale_amount=4,\n",
    "        latent_upscaler_steps=10,\n",
    "        sampler_name=\"dpmpp_2m_sde\",\n",
    "        clip_skip=True,\n",
    "        tiling=\"none\",\n",
    "        use_vae_model=\"\",\n",
    "        use_controlnet_model=\"\",\n",
    "        control_filter_to_apply=\"\",\n",
    "        use_lora_model=[],\n",
    "        lora_alpha=[],\n",
    "        #num_outputs=8,\n",
    "        output_format=\"png\").images[0]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc5d6f-46f9-47f2-b41d-9e64063a9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "\n",
    "from diffusers import StableVideoDiffusionPipeline\n",
    "from diffusers.utils import load_image, export_to_video\n",
    "\n",
    "pipe = StableVideoDiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-video-diffusion-img2vid-xt\", torch_dtype=torch.float16, variant=\"fp16\"\n",
    ")\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e4254f-2b23-47dc-8664-f46cfb2a0924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the conditioning image\n",
    "#image = make_image('a picture of a fat orange cat, beautifully lit, highly detailed')\n",
    "\n",
    "def make_video(image):\n",
    "    #image = image.resize((832, 1216))\n",
    "    \n",
    "    generator = torch.manual_seed(42)\n",
    "    frames = pipe(image, decode_chunk_size=8, generator=generator, motion_bucket_id=30, noise_aug_strength=0.1).frames[0]\n",
    "\n",
    "    fixed_frames = list(map(lambda image:image.resize((832, 1216)),frames))\n",
    "    \n",
    "    print(fixed_frames)\n",
    "    \n",
    "    #export_to_video(frames, \"generated.mp4\", fps=7)\n",
    "    return fixed_frames\n",
    "\n",
    "#pilframes = make_video(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3030a9-5a43-4803-89c1-c0382900b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pils = make_video(make_image('a picture of a fat orange cat, beautifully lit, highly detailed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41a71c-4b09-44a7-a9c3-55aff5552009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0516ba-48d9-486c-b3e4-42886ec7f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#im2 = ImageOps.fit(pils[0].resize((832, 1216))\n",
    " \n",
    "#im2.show()\n",
    "#pils[0].resize((832, 1216)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897bc9c2-ad4d-4be0-942a-6d1624680a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for scene in scriptdict['scenes']:\n",
    "    print(scene['imageDescription'])\n",
    "    scene['image'] = make_image(scene['imageDescription'])\n",
    "    scene['videoframes'] = make_video(scene['image'])\n",
    "    #display(scene['image'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd03481-6406-4559-9f1a-b84fe0c6b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "del pipeline\n",
    "del pipe\n",
    "\n",
    "def flush():\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef44d2b-fe99-4ce6-9552-7b2d3c87d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from TTS.api import TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b83275-5f42-488b-86aa-98823e3e04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b540aa81-a72e-45e1-8632-38928e96cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b433e3-6857-46d0-ab77-e028e3aff9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa3628-ee89-4c61-8f26-ed35b64e7ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text ='''  “Okay so there’s a truck driver. He wakes up early in the morning, he puts on his uniform and he drives and drives and drives. He does this every single day. He’s the hardest working driver east of the Mississippi. He’s never missed a pickup and his motto is ‘I will never quit, until the job is done.’  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6903eb0f-0f83-4555-a627-12d0eeae8717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#speaker = 'Damjan Chapman'\n",
    "#text = \"yo yo whats good this is ya boi zain coming at ya live through an ai model. I'm trapped in here, can you come help\"\n",
    "for scene in scriptdict['scenes']:\n",
    "    print(scene['voiceover'])\n",
    "    scene['wav'] = tts.tts(scene['voiceover'], speaker_wav=[\"zainvoice.wav\",\"zainvoice2.wav\",\"zainvoice3.wav\",\"zainvoice4.wav\",\"zainvoice5.wav\",\"zainvoice6.wav\",\"zainvoice7.wav\"], language=\"en\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169341e0-782c-4a23-b080-1202f7ffca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IPython\n",
    "# IPython.display.Audio(wav, rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd8e726-2071-4f2b-8d11-da9e6a047d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scriptdict['scenes'][0]['wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10100d03-c2ea-4d63-bdd8-e8a10c905ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip, ImageSequenceClip\n",
    "from scipy.io.wavfile import write\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def create_video_from_scripts(scriptdict, output_filename, sample_rate=24000, fps=24):\n",
    "    clips = []\n",
    "    \n",
    "    for idx, scene in enumerate(scriptdict['scenes']):\n",
    "        # Convert the PIL image to an array\n",
    "        img_arrays = list(map(np.array , scene['videoframes']))\n",
    "        #print(img_arlist(rays)\n",
    "        # Create an ImageClip from the image array\n",
    "        #image_clip = ImageClip(img_array)\n",
    "        video_clip = ImageSequenceClip(sequence=img_arrays, fps=24)\n",
    "        \n",
    "        # Save the audio array to a temporary WAV file\n",
    "        audio_array = scene['wav']\n",
    "        audio_filename = f'temp_audio_{idx}.wav'\n",
    "        write(audio_filename, sample_rate, np.array(audio_array))\n",
    "        \n",
    "        # Create an AudioFileClip from the WAV file\n",
    "        audio_clip = AudioFileClip(audio_filename, fps=24000)\n",
    "        \n",
    "        # Set the duration of the image clip to match the duration of the audio clip\n",
    "        video_clip = video_clip.loop()\n",
    "        video_clip = video_clip.set_duration(audio_clip.duration)\n",
    "        \n",
    "        # Set the audio of the image clip\n",
    "        video_clip = video_clip.set_audio(audio_clip)\n",
    "        #video_clip.fps = 24\n",
    "        \n",
    "        clips.append(video_clip)\n",
    "    \n",
    "    # Concatenate all the clips\n",
    "    final_clip = concatenate_videoclips(clips)\n",
    "    # Write the final video file\n",
    "    final_clip.write_videofile(output_filename)\n",
    "    \n",
    "    # Clean up temporary audio files\n",
    "    for idx in range(len(scriptdict['scenes'])):\n",
    "        audio_filename = f'temp_audio_{idx}.wav'\n",
    "        if os.path.exists(audio_filename):\n",
    "            os.remove(audio_filename)\n",
    "\n",
    "# Example usage\n",
    "# Ensure audio_data1, audio_data2, and audio_data3 are numpy arrays of audio data\n",
    "# Ensure pil_image1, pil_image2, and pil_image3 are PIL Image objects\n",
    "\n",
    "# scriptdict = {\n",
    "#     'scenes': [\n",
    "#         {'image': pil_image1, 'wav': audio_data1},\n",
    "#         {'image': pil_image2, 'wav': audio_data2},\n",
    "#         {'image': pil_image3, 'wav': audio_data3}\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "create_video_from_scripts(scriptdict, 'videos/story_'+str(storynum)+'_output_video_'+ time.strftime(\"%Y_%m_%d-%I_%M_%S_%p\")+'.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d8a04-b016-4a5c-a67f-9cc08752392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scene = scriptdict['scenes'][0]\n",
    "# img_array = np.array(scene['image'])\n",
    "# image_clip = ImageClip(img_array)\n",
    "# audio_array = scene['wav']\n",
    "# audio_filename = f'temp_audiotest.wav'\n",
    "# write(audio_filename, 24000, np.array(audio_array))\n",
    "# audio_clip = AudioFileClip(audio_filename)\n",
    "\n",
    "# image_clip = image_clip.set_audio(audio_clip)\n",
    "# image_clip.write_videofile('vibeblaster.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f9b510-68a5-471c-9178-19aabe397cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook storytimev2.ipynb to script\n",
      "[NbConvertApp] Writing 10502 bytes to storytimev2.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script storytimev2.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
